{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "from capi import api_key\n",
    "\n",
    "from models.gan_models import *\n",
    "import yfinance as yf\n",
    "import MetaTrader5 as mt5\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = os.environ['COMET_API_KEY']\n",
    "#api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/c0796ccd7b334eb2a0bd399521c9a8df\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Whole Train [11]  : (0.2500037994495658, 2903.2679585454075)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Whole Train [11] : (0.24998955896427466, 2909.2278901744785)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [202]                      : (0.006200707517564297, 3570.6318359375)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (53.16 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/tail-price/2ea2808c9bcb43dca53386e8e9869302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=api_key,\n",
    "  project_name=\"tail-price\",\n",
    "  workspace=\"artaasd95\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading current tf data\n"
     ]
    }
   ],
   "source": [
    "mt5.initialize()\n",
    "\n",
    "print('loading current tf data')\n",
    "utc_from = datetime(2021, 1, 1, tzinfo=pytz.timezone(\"Asia/Nicosia\"))\n",
    "utc_to = datetime.now(pytz.timezone(\"Asia/Nicosia\"))\n",
    "\n",
    "data = mt5.copy_rates_range('XAUUSD', mt5.TIMEFRAME_H4, utc_from, utc_to)\n",
    "data = pd.DataFrame(data)\n",
    "time_data = data.time\n",
    "data.drop(columns=['tick_volume', 'spread', 'real_volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1609718400</td>\n",
       "      <td>1904.48</td>\n",
       "      <td>1918.60</td>\n",
       "      <td>1900.62</td>\n",
       "      <td>1916.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1609732800</td>\n",
       "      <td>1916.65</td>\n",
       "      <td>1925.15</td>\n",
       "      <td>1915.44</td>\n",
       "      <td>1921.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1609747200</td>\n",
       "      <td>1921.52</td>\n",
       "      <td>1935.09</td>\n",
       "      <td>1921.34</td>\n",
       "      <td>1932.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1609761600</td>\n",
       "      <td>1931.95</td>\n",
       "      <td>1942.06</td>\n",
       "      <td>1927.79</td>\n",
       "      <td>1939.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1609776000</td>\n",
       "      <td>1939.78</td>\n",
       "      <td>1944.33</td>\n",
       "      <td>1929.23</td>\n",
       "      <td>1936.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>5582</td>\n",
       "      <td>1723780800</td>\n",
       "      <td>2458.38</td>\n",
       "      <td>2459.97</td>\n",
       "      <td>2450.72</td>\n",
       "      <td>2452.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>5583</td>\n",
       "      <td>1723795200</td>\n",
       "      <td>2452.68</td>\n",
       "      <td>2464.50</td>\n",
       "      <td>2451.11</td>\n",
       "      <td>2462.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>5584</td>\n",
       "      <td>1723809600</td>\n",
       "      <td>2462.32</td>\n",
       "      <td>2492.34</td>\n",
       "      <td>2461.17</td>\n",
       "      <td>2491.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>5585</td>\n",
       "      <td>1723824000</td>\n",
       "      <td>2491.46</td>\n",
       "      <td>2500.08</td>\n",
       "      <td>2477.46</td>\n",
       "      <td>2495.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>5586</td>\n",
       "      <td>1723838400</td>\n",
       "      <td>2495.84</td>\n",
       "      <td>2509.68</td>\n",
       "      <td>2493.12</td>\n",
       "      <td>2506.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5587 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        time     open     high      low    close\n",
       "0              0  1609718400  1904.48  1918.60  1900.62  1916.57\n",
       "1              1  1609732800  1916.65  1925.15  1915.44  1921.56\n",
       "2              2  1609747200  1921.52  1935.09  1921.34  1932.03\n",
       "3              3  1609761600  1931.95  1942.06  1927.79  1939.75\n",
       "4              4  1609776000  1939.78  1944.33  1929.23  1936.92\n",
       "...          ...         ...      ...      ...      ...      ...\n",
       "5582        5582  1723780800  2458.38  2459.97  2450.72  2452.68\n",
       "5583        5583  1723795200  2452.68  2464.50  2451.11  2462.32\n",
       "5584        5584  1723809600  2462.32  2492.34  2461.17  2491.49\n",
       "5585        5585  1723824000  2491.46  2500.08  2477.46  2495.82\n",
       "5586        5586  1723838400  2495.84  2509.68  2493.12  2506.82\n",
       "\n",
       "[5587 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 512\n",
    "seq_length = 50\n",
    "num_layers = 8\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize models\n",
    "main_gen = MainGenerator(input_size, hidden_size, num_layers, 0.5, 1)\n",
    "noise_gen = NoiseGenerator(input_size, 512, 1, 0.5)\n",
    "discriminator = Discriminator(input_size, hidden_size, num_layers, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (lstm): LSTM(1, 512, num_layers=8, batch_first=True, dropout=0.5)\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_gen.to(device)\n",
    "noise_gen.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.AdamW(list(main_gen.parameters()) + list(noise_gen.parameters()), lr=learning_rate)\n",
    "optimizer_D = torch.optim.AdamW(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "optim_g_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_G, 0.2)\n",
    "optim_d_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_D, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy_dist = torch.distributions.cauchy.Cauchy(loc=0, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adversarial_loss = F.kl_div\n",
    "adversarial_loss = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(len(data)*0.7)]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = data[int(len(data)*0.7):]\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(train_data)/batch_size)-1):\n",
    "        price = torch.tensor(train_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "        # Generate fake data\n",
    "        fake_main = main_gen(price)\n",
    "        fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "\n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]  Discriminator Loss: 385699.9375  Generator Loss: 382206.8125\n"
     ]
    }
   ],
   "source": [
    "# Test loop\n",
    "batch_start = 0\n",
    "for idx in range(int(len(test_data)/batch_size)-1):\n",
    "    price = torch.tensor(test_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "    price = price.to(device)\n",
    "    batch_start = batch_start + batch_size\n",
    "    # Generate random noise inputs\n",
    "    z1 = cauchy_dist.sample([batch_size, 1])\n",
    "    z1 = z1.to(device)\n",
    "    #z2 = cauchy_dist.sample([1])\n",
    "    main_gen.eval()\n",
    "    noise_gen.eval()\n",
    "    discriminator.eval()\n",
    "    # Generate fake data\n",
    "    fake_main = main_gen(price)\n",
    "    fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "    fake_data = fake_main + fake_noise\n",
    "\n",
    "\n",
    "    #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "    d_loss = adversarial_loss(discriminator(fake_data), price)\n",
    "    g_loss = adversarial_loss(price, fake_data)\n",
    "    noise_loss = adversarial_loss(fake_noise, z1)\n",
    "    total_loss = 0.5 * ((0.8 * g_loss + 0.2 * noise_loss) + d_loss)\n",
    "    optimizer_G.step()\n",
    "\n",
    "optim_g_sched.step()\n",
    "optim_d_sched.step()\n",
    "\n",
    "print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {d_loss.item():.4f}  Generator Loss: {g_loss.item():.4f}\")\n",
    "experiment.log_metric('Main Generator\\Test', g_loss, step=epoch)\n",
    "experiment.log_metric('Noise Generator\\Test', noise_loss, step=epoch)\n",
    "experiment.log_metric('Discriminator\\Test', d_loss, step=epoch)\n",
    "experiment.log_metric('Total\\Test', total_loss, step=epoch)\n",
    "# log_model(experiment, model=main_gen, model_name=\"Main Generator\")\n",
    "# log_model(experiment, model=noise_gen, model_name=\"Noise Generator\")\n",
    "# log_model(experiment, model=discriminator, model_name=\"Discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/29faec1725b4493eae8c3f8cb9469e86\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Test          : 385699.9375\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Train [100]   : (8.331120317632502, 308944.53143544035)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Test         : 382206.8125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Train [100]  : (13899.041346526343, 328724.9913884943)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Test        : 18.316530227661133\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Train [100] : (56.87691254064071, 4107405.4870138187)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Test                  : 345734.53125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Train [100]           : (5569.589484600981, 416304.47764398245)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [2420]                 : (0.012668007984757423, 3029160.5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (41.37 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0101],\n",
       "        [-0.0103],\n",
       "        [-0.0096],\n",
       "        [-0.0094],\n",
       "        [-0.0103],\n",
       "        [-0.0105],\n",
       "        [-0.0093],\n",
       "        [-0.0099],\n",
       "        [-0.0103],\n",
       "        [-0.0099],\n",
       "        [-0.0113],\n",
       "        [-0.0103],\n",
       "        [-0.0101],\n",
       "        [-0.0094],\n",
       "        [-0.0090],\n",
       "        [-0.0095],\n",
       "        [-0.0107],\n",
       "        [-0.0094],\n",
       "        [-0.0094],\n",
       "        [-0.0098],\n",
       "        [-0.0105],\n",
       "        [-0.0083],\n",
       "        [-0.0101],\n",
       "        [-0.0092],\n",
       "        [-0.0101],\n",
       "        [-0.0104],\n",
       "        [-0.0108],\n",
       "        [-0.0123],\n",
       "        [-0.0113],\n",
       "        [-0.0087],\n",
       "        [-0.0087],\n",
       "        [-0.0095],\n",
       "        [-0.0084],\n",
       "        [-0.0096],\n",
       "        [-0.0091],\n",
       "        [-0.0101],\n",
       "        [-0.0095],\n",
       "        [-0.0112],\n",
       "        [-0.0083],\n",
       "        [-0.0116],\n",
       "        [-0.0091],\n",
       "        [-0.0101],\n",
       "        [-0.0104],\n",
       "        [-0.0097],\n",
       "        [-0.0090],\n",
       "        [-0.0107],\n",
       "        [-0.0095],\n",
       "        [-0.0093],\n",
       "        [-0.0080],\n",
       "        [-0.0103],\n",
       "        [-0.0108],\n",
       "        [-0.0090],\n",
       "        [-0.0101],\n",
       "        [-0.0099],\n",
       "        [-0.0095],\n",
       "        [-0.0109],\n",
       "        [-0.0093],\n",
       "        [-0.0099],\n",
       "        [-0.0096],\n",
       "        [-0.0085],\n",
       "        [-0.0095],\n",
       "        [-0.0103],\n",
       "        [-0.0089],\n",
       "        [-0.0117]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = cauchy_dist.sample([batch_size, 1])\n",
    "z1 = z1.to(device)\n",
    "z1[0].item()\n",
    "fake_main = main_gen(z1)\n",
    "fake_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:18<14:48, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Discriminator Loss: 1.4940630661886791  Generator Loss: 1.49936834111983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:36<14:35, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]  Discriminator Loss: 0.25098552173653316  Generator Loss: 0.251523227885712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:54<14:16, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]  Discriminator Loss: 0.25111162367948264  Generator Loss: 0.24981914876505387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:12<13:58, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]  Discriminator Loss: 0.24995943505403606  Generator Loss: 0.25012327020251474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:19<15:15, 19.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m adversarial_loss(discriminator(fake_data), valid)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# g_loss = torch.sum(g_loss_norm)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Train generators\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\torchgpu\\lib\\site-packages\\comet_ml\\monkey_patching.py:324\u001b[0m, in \u001b[0;36mEntrypoint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m exception_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    326\u001b[0m     exception_raised \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\torchgpu\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\torchgpu\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(data)/batch_size)-1):\n",
    "        price = torch.tensor(data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        #price = torch.tensor(random.sample(list(data[batch_start:batch_start+batch_size].close.values), batch_size), dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1, device=device)\n",
    "        fake = torch.zeros(batch_size, 1, device=device)\n",
    "        # Generate fake data\n",
    "        #fake_main = main_gen(price)\n",
    "        fake_main = main_gen(z1)\n",
    "        fake_noise = noise_gen(z1)\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        #noise_loss = adversarial_loss(fake_noise, z1)\n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        #g_loss_data = adversarial_loss(fake_main, price)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "\n",
    "        # g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\n",
    "        # g_loss = torch.sum(g_loss_norm)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        \n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Whole Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Whole Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/9f49e2d15e38475cabcfe319809b5eec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Whole Train [50]  : (0.25955625224945156, 3416.939735186308)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Whole Train [50] : (0.26196861267089844, 3422.574053081056)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [860]                      : (0.2567949593067169, 10879.6005859375)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (37.64 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(main_gen, 'checkpoints/main_gen_xau.pth')\n",
    "torch.save(noise_gen, 'checkpoints/noise_gen_xau.pth')\n",
    "torch.save(discriminator, 'checkpoints/discriminator_xau.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
