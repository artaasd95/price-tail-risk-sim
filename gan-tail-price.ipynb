{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "\n",
    "from models.gan_models import *\n",
    "import yfinance as yf\n",
    "import MetaTrader5 as mt5\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['COMET_API_KEY']\n",
    "#api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/tail-price/9f49e2d15e38475cabcfe319809b5eec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=api_key,\n",
    "  project_name=\"tail-price\",\n",
    "  workspace=\"artaasd95\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading current tf data\n"
     ]
    }
   ],
   "source": [
    "mt5.initialize()\n",
    "\n",
    "print('loading current tf data')\n",
    "utc_from = datetime(2021, 1, 1, tzinfo=pytz.timezone(\"Asia/Nicosia\"))\n",
    "utc_to = datetime.now(pytz.timezone(\"Asia/Nicosia\"))\n",
    "\n",
    "data = mt5.copy_rates_range('XAUUSD', mt5.TIMEFRAME_H4, utc_from, utc_to)\n",
    "data = pd.DataFrame(data)\n",
    "time_data = data.time\n",
    "data.drop(columns=['tick_volume', 'spread', 'real_volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1609718400</td>\n",
       "      <td>1904.48</td>\n",
       "      <td>1918.60</td>\n",
       "      <td>1900.62</td>\n",
       "      <td>1916.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1609732800</td>\n",
       "      <td>1916.65</td>\n",
       "      <td>1925.15</td>\n",
       "      <td>1915.44</td>\n",
       "      <td>1921.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1609747200</td>\n",
       "      <td>1921.52</td>\n",
       "      <td>1935.09</td>\n",
       "      <td>1921.34</td>\n",
       "      <td>1932.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1609761600</td>\n",
       "      <td>1931.95</td>\n",
       "      <td>1942.06</td>\n",
       "      <td>1927.79</td>\n",
       "      <td>1939.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1609776000</td>\n",
       "      <td>1939.78</td>\n",
       "      <td>1944.33</td>\n",
       "      <td>1929.23</td>\n",
       "      <td>1936.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>5582</td>\n",
       "      <td>1723780800</td>\n",
       "      <td>2458.38</td>\n",
       "      <td>2459.97</td>\n",
       "      <td>2450.72</td>\n",
       "      <td>2452.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>5583</td>\n",
       "      <td>1723795200</td>\n",
       "      <td>2452.68</td>\n",
       "      <td>2464.50</td>\n",
       "      <td>2451.11</td>\n",
       "      <td>2462.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>5584</td>\n",
       "      <td>1723809600</td>\n",
       "      <td>2462.32</td>\n",
       "      <td>2492.34</td>\n",
       "      <td>2461.17</td>\n",
       "      <td>2491.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>5585</td>\n",
       "      <td>1723824000</td>\n",
       "      <td>2491.46</td>\n",
       "      <td>2500.08</td>\n",
       "      <td>2477.46</td>\n",
       "      <td>2495.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>5586</td>\n",
       "      <td>1723838400</td>\n",
       "      <td>2495.84</td>\n",
       "      <td>2509.68</td>\n",
       "      <td>2493.12</td>\n",
       "      <td>2506.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5587 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        time     open     high      low    close\n",
       "0              0  1609718400  1904.48  1918.60  1900.62  1916.57\n",
       "1              1  1609732800  1916.65  1925.15  1915.44  1921.56\n",
       "2              2  1609747200  1921.52  1935.09  1921.34  1932.03\n",
       "3              3  1609761600  1931.95  1942.06  1927.79  1939.75\n",
       "4              4  1609776000  1939.78  1944.33  1929.23  1936.92\n",
       "...          ...         ...      ...      ...      ...      ...\n",
       "5582        5582  1723780800  2458.38  2459.97  2450.72  2452.68\n",
       "5583        5583  1723795200  2452.68  2464.50  2451.11  2462.32\n",
       "5584        5584  1723809600  2462.32  2492.34  2461.17  2491.49\n",
       "5585        5585  1723824000  2491.46  2500.08  2477.46  2495.82\n",
       "5586        5586  1723838400  2495.84  2509.68  2493.12  2506.82\n",
       "\n",
       "[5587 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1024\n",
    "seq_length = 50\n",
    "num_layers = 12\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize models\n",
    "main_gen = MainGenerator(input_size, hidden_size, num_layers, 0.5, 1)\n",
    "noise_gen = NoiseGenerator(input_size, 2048, 1, 0.4)\n",
    "discriminator = Discriminator(input_size, hidden_size, 15, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (lstm): LSTM(1, 1024, num_layers=15, batch_first=True, dropout=0.4)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_gen.to(device)\n",
    "noise_gen.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.AdamW(list(main_gen.parameters()) + list(noise_gen.parameters()), lr=learning_rate)\n",
    "optimizer_D = torch.optim.AdamW(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "optim_g_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_G, 0.5)\n",
    "optim_d_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_D, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy_dist = torch.distributions.cauchy.Cauchy(loc=0, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adversarial_loss = F.kl_div\n",
    "adversarial_loss = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(len(data)*0.7)]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = data[int(len(data)*0.7):]\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(train_data)/batch_size)-1):\n",
    "        price = torch.tensor(train_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "        # Generate fake data\n",
    "        fake_main = main_gen(price)\n",
    "        fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "\n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]  Discriminator Loss: 385699.9375  Generator Loss: 382206.8125\n"
     ]
    }
   ],
   "source": [
    "# Test loop\n",
    "batch_start = 0\n",
    "for idx in range(int(len(test_data)/batch_size)-1):\n",
    "    price = torch.tensor(test_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "    price = price.to(device)\n",
    "    batch_start = batch_start + batch_size\n",
    "    # Generate random noise inputs\n",
    "    z1 = cauchy_dist.sample([batch_size, 1])\n",
    "    z1 = z1.to(device)\n",
    "    #z2 = cauchy_dist.sample([1])\n",
    "    main_gen.eval()\n",
    "    noise_gen.eval()\n",
    "    discriminator.eval()\n",
    "    # Generate fake data\n",
    "    fake_main = main_gen(price)\n",
    "    fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "    fake_data = fake_main + fake_noise\n",
    "\n",
    "\n",
    "    #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "    d_loss = adversarial_loss(discriminator(fake_data), price)\n",
    "    g_loss = adversarial_loss(price, fake_data)\n",
    "    noise_loss = adversarial_loss(fake_noise, z1)\n",
    "    total_loss = 0.5 * ((0.8 * g_loss + 0.2 * noise_loss) + d_loss)\n",
    "    optimizer_G.step()\n",
    "\n",
    "optim_g_sched.step()\n",
    "optim_d_sched.step()\n",
    "\n",
    "print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {d_loss.item():.4f}  Generator Loss: {g_loss.item():.4f}\")\n",
    "experiment.log_metric('Main Generator\\Test', g_loss, step=epoch)\n",
    "experiment.log_metric('Noise Generator\\Test', noise_loss, step=epoch)\n",
    "experiment.log_metric('Discriminator\\Test', d_loss, step=epoch)\n",
    "experiment.log_metric('Total\\Test', total_loss, step=epoch)\n",
    "# log_model(experiment, model=main_gen, model_name=\"Main Generator\")\n",
    "# log_model(experiment, model=noise_gen, model_name=\"Noise Generator\")\n",
    "# log_model(experiment, model=discriminator, model_name=\"Discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/29faec1725b4493eae8c3f8cb9469e86\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Test          : 385699.9375\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Train [100]   : (8.331120317632502, 308944.53143544035)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Test         : 382206.8125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Train [100]  : (13899.041346526343, 328724.9913884943)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Test        : 18.316530227661133\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Train [100] : (56.87691254064071, 4107405.4870138187)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Test                  : 345734.53125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Train [100]           : (5569.589484600981, 416304.47764398245)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [2420]                 : (0.012668007984757423, 3029160.5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (41.37 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:51<42:19, 51.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Discriminator Loss: 3416.939735186308  Generator Loss: 3422.574053081056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:43<41:11, 51.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]  Discriminator Loss: 0.45133022236269577  Generator Loss: 0.4539188072518554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [02:34<40:18, 51.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]  Discriminator Loss: 0.26090639067250626  Generator Loss: 0.2640473729995794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [03:25<39:23, 51.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]  Discriminator Loss: 0.260206522983174  Generator Loss: 0.26322780202987583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [04:17<38:35, 51.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]  Discriminator Loss: 0.2598791950663855  Generator Loss: 0.2628477541513221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [05:08<37:41, 51.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50]  Discriminator Loss: 0.2597179638091908  Generator Loss: 0.26265591244364894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [05:59<36:48, 51.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50]  Discriminator Loss: 0.2596375751633977  Generator Loss: 0.2625531983930011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [06:51<35:54, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50]  Discriminator Loss: 0.2595971347980721  Generator Loss: 0.2624884909668634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [07:42<35:03, 51.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50]  Discriminator Loss: 0.2595767701087996  Generator Loss: 0.2624245438464852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [08:33<34:14, 51.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50]  Discriminator Loss: 0.2595664803371873  Generator Loss: 0.2624098537273185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [09:25<33:25, 51.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50]  Discriminator Loss: 0.25956136092197063  Generator Loss: 0.2624712669572165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [10:17<32:36, 51.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50]  Discriminator Loss: 0.2595587764368501  Generator Loss: 0.26253143403419227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [11:07<31:29, 51.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50]  Discriminator Loss: 0.25955768969169885  Generator Loss: 0.26284544204556665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [11:56<30:21, 50.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50]  Discriminator Loss: 0.25955748107544213  Generator Loss: 0.2632567043914351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [12:46<29:21, 50.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50]  Discriminator Loss: 0.25955679596856585  Generator Loss: 0.26300582116426424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [13:36<28:25, 50.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50]  Discriminator Loss: 0.25955625224945156  Generator Loss: 0.2623118297305218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [14:26<27:32, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50]  Discriminator Loss: 0.25955629348754883  Generator Loss: 0.2619686424732208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [15:15<26:40, 50.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50]  Discriminator Loss: 0.2595562751210013  Generator Loss: 0.2619686241066733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [16:05<25:48, 49.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [16:55<24:58, 49.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [17:45<24:08, 49.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [18:35<23:19, 49.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [19:25<22:29, 49.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [20:15<21:40, 50.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [21:05<20:51, 50.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [21:55<20:01, 50.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [22:46<19:11, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [23:36<18:21, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [24:26<17:32, 50.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [25:16<16:42, 50.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [26:06<15:53, 50.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [26:57<15:04, 50.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [27:45<14:03, 49.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [28:33<13:06, 49.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [29:21<12:13, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [30:09<11:20, 48.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [30:57<10:29, 48.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [31:45<09:39, 48.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [32:33<08:50, 48.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [33:21<08:02, 48.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [34:10<07:13, 48.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [34:58<06:25, 48.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [35:46<05:37, 48.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [36:34<04:49, 48.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [37:22<04:01, 48.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [38:10<03:12, 48.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [38:59<02:24, 48.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [39:47<01:36, 48.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [40:35<00:48, 48.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [41:23<00:00, 49.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50]  Discriminator Loss: 0.25955626368522644  Generator Loss: 0.26196861267089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(data)/batch_size)-1):\n",
    "        price = torch.tensor(data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        #price = torch.tensor(random.sample(list(data[batch_start:batch_start+batch_size].close.values), batch_size), dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1, device=device)\n",
    "        fake = torch.zeros(batch_size, 1, device=device)\n",
    "        # Generate fake data\n",
    "        #fake_main = main_gen(price)\n",
    "        fake_main = main_gen(z1)\n",
    "        fake_noise = noise_gen(z1)\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        #noise_loss = adversarial_loss(fake_noise, z1)\n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        #g_loss_data = adversarial_loss(fake_main, price)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "\n",
    "        # g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\n",
    "        # g_loss = torch.sum(g_loss_norm)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        \n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Whole Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Whole Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/9f49e2d15e38475cabcfe319809b5eec\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Whole Train [50]  : (0.25955625224945156, 3416.939735186308)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Whole Train [50] : (0.26196861267089844, 3422.574053081056)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [860]                      : (0.2567949593067169, 10879.6005859375)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (37.64 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(main_gen, 'checkpoints/main_gen_xau.pth')\n",
    "torch.save(noise_gen, 'checkpoints/noise_gen_xau.pth')\n",
    "torch.save(discriminator, 'checkpoints/discriminator_xau.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
