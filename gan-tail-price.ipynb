{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "\n",
    "from models.gan_models import *\n",
    "import yfinance as yf\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = os.environ['COMET_API_KEY']\n",
    "api_key = 'vpNJF6XOWcHS6HqH9ZFEjwRcD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/tail-price/0e3b3779ac364200aa2f89e9bfba43c6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=api_key,\n",
    "  project_name=\"tail-price\",\n",
    "  workspace=\"artaasd95\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading current tf data\n"
     ]
    }
   ],
   "source": [
    "mt5.initialize()\n",
    "\n",
    "print('loading current tf data')\n",
    "utc_from = datetime(2021, 1, 1, tzinfo=pytz.timezone(\"Asia/Nicosia\"))\n",
    "utc_to = datetime.now(pytz.timezone(\"Asia/Nicosia\"))\n",
    "\n",
    "data = mt5.copy_rates_range('XAUUSD', mt5.TIMEFRAME_H4, utc_from, utc_to)\n",
    "data = pd.DataFrame(data)\n",
    "time_data = data.time\n",
    "data.drop(columns=['tick_volume', 'spread', 'real_volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('xau_2021_H4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1609718400</td>\n",
       "      <td>1904.48</td>\n",
       "      <td>1918.60</td>\n",
       "      <td>1900.62</td>\n",
       "      <td>1916.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1609732800</td>\n",
       "      <td>1916.65</td>\n",
       "      <td>1925.15</td>\n",
       "      <td>1915.44</td>\n",
       "      <td>1921.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1609747200</td>\n",
       "      <td>1921.52</td>\n",
       "      <td>1935.09</td>\n",
       "      <td>1921.34</td>\n",
       "      <td>1932.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1609761600</td>\n",
       "      <td>1931.95</td>\n",
       "      <td>1942.06</td>\n",
       "      <td>1927.79</td>\n",
       "      <td>1939.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1609776000</td>\n",
       "      <td>1939.78</td>\n",
       "      <td>1944.33</td>\n",
       "      <td>1929.23</td>\n",
       "      <td>1936.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>5582</td>\n",
       "      <td>1723780800</td>\n",
       "      <td>2458.38</td>\n",
       "      <td>2459.97</td>\n",
       "      <td>2450.72</td>\n",
       "      <td>2452.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>5583</td>\n",
       "      <td>1723795200</td>\n",
       "      <td>2452.68</td>\n",
       "      <td>2464.50</td>\n",
       "      <td>2451.11</td>\n",
       "      <td>2462.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>5584</td>\n",
       "      <td>1723809600</td>\n",
       "      <td>2462.32</td>\n",
       "      <td>2492.34</td>\n",
       "      <td>2461.17</td>\n",
       "      <td>2491.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>5585</td>\n",
       "      <td>1723824000</td>\n",
       "      <td>2491.46</td>\n",
       "      <td>2500.08</td>\n",
       "      <td>2477.46</td>\n",
       "      <td>2495.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>5586</td>\n",
       "      <td>1723838400</td>\n",
       "      <td>2495.84</td>\n",
       "      <td>2509.68</td>\n",
       "      <td>2493.12</td>\n",
       "      <td>2506.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5587 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        time     open     high      low    close\n",
       "0              0  1609718400  1904.48  1918.60  1900.62  1916.57\n",
       "1              1  1609732800  1916.65  1925.15  1915.44  1921.56\n",
       "2              2  1609747200  1921.52  1935.09  1921.34  1932.03\n",
       "3              3  1609761600  1931.95  1942.06  1927.79  1939.75\n",
       "4              4  1609776000  1939.78  1944.33  1929.23  1936.92\n",
       "...          ...         ...      ...      ...      ...      ...\n",
       "5582        5582  1723780800  2458.38  2459.97  2450.72  2452.68\n",
       "5583        5583  1723795200  2452.68  2464.50  2451.11  2462.32\n",
       "5584        5584  1723809600  2462.32  2492.34  2461.17  2491.49\n",
       "5585        5585  1723824000  2491.46  2500.08  2477.46  2495.82\n",
       "5586        5586  1723838400  2495.84  2509.68  2493.12  2506.82\n",
       "\n",
       "[5587 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1024\n",
    "seq_length = 50\n",
    "num_layers = 12\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.3\n",
    "\n",
    "# Initialize models\n",
    "main_gen = MainGenerator(input_size, hidden_size, num_layers, 0.5, 1)\n",
    "noise_gen = NoiseGenerator(input_size, 2048, 1, 0.4)\n",
    "discriminator = Discriminator(input_size, hidden_size, 15, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (lstm): LSTM(1, 1024, num_layers=15, batch_first=True, dropout=0.4)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_gen.to(device)\n",
    "noise_gen.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.AdamW(list(main_gen.parameters()) + list(noise_gen.parameters()), lr=learning_rate)\n",
    "optimizer_D = torch.optim.AdamW(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "optim_g_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_G, 0.1)\n",
    "optim_d_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer_D, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy_dist = torch.distributions.cauchy.Cauchy(loc=0, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adversarial_loss = F.kl_div\n",
    "adversarial_loss = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(len(data)*0.7)]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = data[int(len(data)*0.7):]\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(train_data)/batch_size)-1):\n",
    "        price = torch.tensor(train_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1)\n",
    "        fake = torch.zeros(batch_size, 1)\n",
    "        # Generate fake data\n",
    "        fake_main = main_gen(price)\n",
    "        fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "\n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]  Discriminator Loss: 385699.9375  Generator Loss: 382206.8125\n"
     ]
    }
   ],
   "source": [
    "# Test loop\n",
    "batch_start = 0\n",
    "for idx in range(int(len(test_data)/batch_size)-1):\n",
    "    price = torch.tensor(test_data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "    price = price.to(device)\n",
    "    batch_start = batch_start + batch_size\n",
    "    # Generate random noise inputs\n",
    "    z1 = cauchy_dist.sample([batch_size, 1])\n",
    "    z1 = z1.to(device)\n",
    "    #z2 = cauchy_dist.sample([1])\n",
    "    main_gen.eval()\n",
    "    noise_gen.eval()\n",
    "    discriminator.eval()\n",
    "    # Generate fake data\n",
    "    fake_main = main_gen(price)\n",
    "    fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "    fake_data = fake_main + fake_noise\n",
    "\n",
    "\n",
    "    #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "    #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "    d_loss = adversarial_loss(discriminator(fake_data), price)\n",
    "    g_loss = adversarial_loss(price, fake_data)\n",
    "    noise_loss = adversarial_loss(fake_noise, z1)\n",
    "    total_loss = 0.5 * ((0.8 * g_loss + 0.2 * noise_loss) + d_loss)\n",
    "    optimizer_G.step()\n",
    "\n",
    "optim_g_sched.step()\n",
    "optim_d_sched.step()\n",
    "\n",
    "print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {d_loss.item():.4f}  Generator Loss: {g_loss.item():.4f}\")\n",
    "experiment.log_metric('Main Generator\\Test', g_loss, step=epoch)\n",
    "experiment.log_metric('Noise Generator\\Test', noise_loss, step=epoch)\n",
    "experiment.log_metric('Discriminator\\Test', d_loss, step=epoch)\n",
    "experiment.log_metric('Total\\Test', total_loss, step=epoch)\n",
    "# log_model(experiment, model=main_gen, model_name=\"Main Generator\")\n",
    "# log_model(experiment, model=noise_gen, model_name=\"Noise Generator\")\n",
    "# log_model(experiment, model=discriminator, model_name=\"Discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/29faec1725b4493eae8c3f8cb9469e86\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Test          : 385699.9375\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Train [100]   : (8.331120317632502, 308944.53143544035)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Test         : 382206.8125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Train [100]  : (13899.041346526343, 328724.9913884943)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Test        : 18.316530227661133\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Noise Generator\\Train [100] : (56.87691254064071, 4107405.4870138187)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Test                  : 345734.53125\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Total\\Train [100]           : (5569.589484600981, 416304.47764398245)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [2420]                 : (0.012668007984757423, 3029160.5)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (41.37 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [08:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# g_loss = torch.sum(g_loss_norm)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 30\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train generators\u001b[39;00m\n\u001b[0;32m     33\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    178\u001b[0m         group,\n\u001b[0;32m    179\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m         state_steps,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     adamw(\n\u001b[0;32m    189\u001b[0m         params_with_grad,\n\u001b[0;32m    190\u001b[0m         grads,\n\u001b[0;32m    191\u001b[0m         exp_avgs,\n\u001b[0;32m    192\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    193\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    194\u001b[0m         state_steps,\n\u001b[0;32m    195\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    196\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    197\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    198\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    199\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    200\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    201\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    202\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    203\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    204\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    205\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    206\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    207\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    208\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 340\u001b[0m func(\n\u001b[0;32m    341\u001b[0m     params,\n\u001b[0;32m    342\u001b[0m     grads,\n\u001b[0;32m    343\u001b[0m     exp_avgs,\n\u001b[0;32m    344\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    345\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    346\u001b[0m     state_steps,\n\u001b[0;32m    347\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    348\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    349\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    350\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    351\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    352\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    353\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    354\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    355\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    356\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    357\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    358\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    359\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arta\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adamw.py:420\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    419\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 420\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    423\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(2)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(data)/batch_size)-1):\n",
    "        price = torch.tensor(data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1, device=device)\n",
    "        fake = torch.zeros(batch_size, 1, device=device)\n",
    "        # Generate fake data\n",
    "        fake_main = main_gen(price)\n",
    "        fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "        fake_data = fake_main + fake_noise\n",
    "        #noise_loss = adversarial_loss(fake_noise, z1)\n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        #g_loss_data = adversarial_loss(fake_main, price)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "\n",
    "        # g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\n",
    "        # g_loss = torch.sum(g_loss_norm)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "\n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\HP\\.conda\\envs\\torchgpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  1%|          | 1/100 [01:06<1:49:55, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:11<1:47:31, 65.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [03:17<1:46:04, 65.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [04:22<1:44:54, 65.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [05:28<1:44:02, 65.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [06:34<1:42:54, 65.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [07:39<1:41:43, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]  Discriminator Loss: 0.5321  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [08:45<1:40:37, 65.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [09:51<1:39:34, 65.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [10:56<1:38:25, 65.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [12:02<1:37:21, 65.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [13:07<1:36:11, 65.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [14:13<1:35:09, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [15:18<1:33:55, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [16:24<1:32:49, 65.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [17:29<1:31:36, 65.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [18:34<1:30:18, 65.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [19:39<1:28:55, 65.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [20:44<1:27:50, 65.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [21:49<1:26:49, 65.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [22:54<1:25:45, 65.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [24:00<1:24:51, 65.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [25:05<1:23:51, 65.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [26:11<1:22:51, 65.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [27:16<1:21:44, 65.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [28:22<1:20:38, 65.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [29:27<1:19:39, 65.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [30:33<1:18:43, 65.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [31:39<1:17:43, 65.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [32:45<1:16:38, 65.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [33:51<1:15:38, 65.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [34:57<1:14:34, 65.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [36:02<1:13:29, 65.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]  Discriminator Loss: 0.5320  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [37:09<1:12:31, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [38:15<1:11:27, 65.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [39:21<1:10:21, 65.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [40:26<1:09:10, 65.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [41:32<1:08:05, 65.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [42:38<1:06:59, 65.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [43:44<1:06:00, 66.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [44:51<1:04:58, 66.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [45:57<1:03:51, 66.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [47:03<1:02:47, 66.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [48:09<1:01:37, 66.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [49:15<1:00:33, 66.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [50:21<59:24, 66.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [51:26<58:15, 65.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [52:32<57:08, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [53:38<56:02, 65.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [54:44<54:56, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [55:50<53:45, 65.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100]  Discriminator Loss: 0.5320  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [56:56<52:40, 65.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [58:02<51:36, 65.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [59:08<50:30, 65.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [1:00:14<49:27, 65.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [1:01:20<48:20, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [1:02:25<47:10, 65.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [1:03:31<46:01, 65.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [1:04:36<44:52, 65.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [1:05:42<43:44, 65.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [1:06:47<42:35, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [1:07:52<41:28, 65.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [1:08:58<40:24, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [1:10:04<39:26, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100]  Discriminator Loss: 0.5314  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [1:11:10<38:20, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [1:12:16<37:15, 65.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [1:13:22<36:13, 65.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [1:14:27<35:05, 65.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [1:15:33<33:54, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [1:16:38<32:45, 65.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [1:17:43<31:38, 65.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [1:18:49<30:34, 65.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [1:19:54<29:27, 65.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [1:21:00<28:21, 65.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [1:22:05<27:16, 65.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [1:23:11<26:11, 65.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [1:24:16<25:07, 65.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [1:25:22<24:02, 65.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [1:26:28<22:59, 65.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100]  Discriminator Loss: 0.5314  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [1:27:34<21:55, 65.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [1:28:40<20:49, 65.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [1:29:45<19:43, 65.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [1:30:51<18:37, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [1:31:57<17:32, 65.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [1:33:03<16:27, 65.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [1:34:09<15:22, 65.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100]  Discriminator Loss: 0.5315  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [1:35:15<14:16, 65.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [1:36:21<13:12, 66.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [1:37:27<12:06, 66.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100]  Discriminator Loss: 0.5318  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [1:38:33<10:59, 65.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100]  Discriminator Loss: 0.5313  Generator Loss: 1.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [1:39:39<09:53, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [1:40:45<08:47, 65.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100]  Discriminator Loss: 0.5320  Generator Loss: 1.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [1:41:51<07:41, 65.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100]  Discriminator Loss: 0.5314  Generator Loss: 1.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [1:42:57<06:36, 66.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [1:44:03<05:30, 66.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [1:45:10<04:24, 66.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100]  Discriminator Loss: 0.5320  Generator Loss: 1.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [1:46:16<03:18, 66.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [1:47:22<02:12, 66.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100]  Discriminator Loss: 0.5319  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [1:48:28<01:06, 66.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100]  Discriminator Loss: 0.5317  Generator Loss: 1.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:49:34<00:00, 65.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]  Discriminator Loss: 0.5316  Generator Loss: 1.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    batch_start = 0\n",
    "    g_loss_list = []\n",
    "    noise_loss_list = []\n",
    "    d_loss_list = []\n",
    "    for idx in range(int(len(data)/batch_size)-1):\n",
    "        price = torch.tensor(data[batch_start:batch_start+batch_size].close.values, dtype=torch.float).reshape(batch_size,1)\n",
    "        price = price.to(device)\n",
    "        batch_start = batch_start + batch_size\n",
    "        # Generate random noise inputs\n",
    "        z1 = cauchy_dist.sample([batch_size, 1])\n",
    "        z1 = z1.to(device)\n",
    "        #z2 = cauchy_dist.sample([1])\n",
    "        valid = torch.ones(batch_size, 1, device=device)\n",
    "        fake = torch.zeros(batch_size, 1, device=device)\n",
    "        # Generate fake data\n",
    "        fake_main = main_gen(price)\n",
    "        fake_noise = noise_gen(torch.rand([batch_size, 1], device=device))\n",
    "        fake_data = fake_main + fake_noise\n",
    "        \n",
    "        noise_loss = adversarial_loss(fake_noise, z1)\n",
    "        # Train discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        #g_loss_data = adversarial_loss(fake_main, price)\n",
    "        g_loss = adversarial_loss(discriminator(fake_data), valid)\n",
    "\n",
    "        # g_loss_norm = F.normalize(torch.tensor([g_loss, g_loss_data]))\n",
    "        # g_loss = torch.sum(g_loss_norm)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train generators\n",
    "        optimizer_D.zero_grad()\n",
    "        #d_loss = adversarial_loss(F.log_softmax(discriminator(fake_data), dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #g_loss = adversarial_loss(F.log_softmax(fake_data, dim=0), F.softmax(price, dim=0), reduction='batchmean')\n",
    "        #noise_loss = adversarial_loss(F.log_softmax(fake_noise, dim=0), F.softmax(z1, dim=0), reduction='batchmean')\n",
    "        \n",
    "        \n",
    "\n",
    "        fake_d_loss = adversarial_loss(discriminator(fake_data.detach()), fake)\n",
    "        valid_d_loss = adversarial_loss(discriminator(price), valid)\n",
    "\n",
    "        d_loss = 0.5 * (fake_d_loss + valid_d_loss)\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        d_loss_list.append(d_loss.item())\n",
    "\n",
    "    optim_g_sched.step()\n",
    "    optim_d_sched.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Discriminator Loss: {np.average(d_loss_list)}  Generator Loss: {np.average(g_loss_list)}\")\n",
    "    experiment.log_metric('Main Generator\\Whole Train', np.average(g_loss_list), step=epoch)\n",
    "    experiment.log_metric('Discriminator\\Whole Train', np.average(d_loss_list), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/tail-price/0e3b3779ac364200aa2f89e9bfba43c6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Discriminator\\Whole Train [100]  : (0.5316601461068743, 0.5317050997232426)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Main Generator\\Whole Train [100] : (1.0623610467580014, 1.0624684157399085)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [3460]                      : (0.5312371253967285, 1.0633294582366943)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (46.91 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(main_gen, 'checkpoints/main_gen_xau.pth')\n",
    "torch.save(noise_gen, 'checkpoints/noise_gen_xau.pth')\n",
    "torch.save(discriminator, 'checkpoints/discriminator_xau.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
